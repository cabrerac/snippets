### Rectified Linear Units

\code{%load -s relu mlai.py}

\displaycode{pods.notebook.display_prediction(basis=relu, num_basis=4)}

\notes{Rectified linear units are popular in the current generation of multilayer perceptron models, or deep networks. These basis functions start flat, and then become linear functions at a certain threshold.}
